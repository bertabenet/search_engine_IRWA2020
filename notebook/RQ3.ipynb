{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, '../search-engine')\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "from igraph import *\n",
    "import implicit\n",
    "from scipy.sparse import csr_matrix\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data \n",
    "data = get_tweets(None, None, mode = \"read\", data_directory = '../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since igraph does not use node ids -> we need to create a dict storing the conversion\n",
    "ids_mapping = {}\n",
    "hashtags = {}\n",
    "counter = 0\n",
    "for tweet in data:\n",
    "    if \"retweeted_status\" in tweet.keys():\n",
    "        if tweet[\"user\"][\"id\"] not in ids_mapping.keys():\n",
    "            ids_mapping[tweet[\"user\"][\"id\"]] = counter            \n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweets = {}\n",
    "for i, tweet in enumerate(data): \n",
    "    try: \n",
    "        id2 = ids_mapping[tweet[\"retweeted_status\"][\"user\"][\"id\"]]        \n",
    "        id1 = ids_mapping[tweet[\"user\"][\"id\"]]\n",
    "        try: retweets[id1].append(id2)\n",
    "        except: retweets[id1] = [id2]\n",
    "    except: \n",
    "        continue\n",
    "    \n",
    "    #try: hashtags[counter] += [tweet[\"entities\"][\"hashtags\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgelist = []\n",
    "for node in retweets:\n",
    "    for i in retweets[node]:\n",
    "        edgelist.append((node, i))\n",
    "edgelist = list(set(edgelist)) # remove duplicated links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Graph(n = len(ids_mapping))\n",
    "g.add_edges(edgelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split graph into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraction of edges to select as test-set\n",
    "p = 0.2\n",
    "\n",
    "# graphsize\n",
    "N = len(g.es)\n",
    "\n",
    "# idxs of all the edges\n",
    "all_idxs = range(N)\n",
    "\n",
    "# sample idxs of edges through the function \"choice\"\n",
    "test_idxs = np.random.choice(a=all_idxs, size=int(p*N),replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = set()\n",
    "trainset = set()\n",
    "for idx, one_edge in enumerate(g.es):\n",
    "    \n",
    "    # take n1 and n2 idx from one_edge, that is an igraph edge *object*\n",
    "    n1 = one_edge.source\n",
    "    n2 = one_edge.target\n",
    "\n",
    "    if idx in test_idxs:\n",
    "        ground_truth.add((n1, n2))\n",
    "    else:\n",
    "        trainset.add((n1, n2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_idxs --> nodes q formen part del test\n",
    "# ground_truth --> links entre els nodes del test set\n",
    "# trainset --> links entre els nodes del train set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nodes_at_distance_2(graph):\n",
    "    \"\"\"\n",
    "    starting from a graph this function returns all the nodes at distance 2\n",
    "    \"\"\"\n",
    "    all_potential_recommendations = set()\n",
    "    \n",
    "    for n1 in graph.vs:\n",
    "        # all the nodes at distance 1 and distance 2\n",
    "        nodes_at_most_distant_2 = set(graph.neighborhood(n1, order = 2))\n",
    "            \n",
    "        if len(nodes_at_most_distant_2) > 0:\n",
    "            for n2 in nodes_at_most_distant_2: \n",
    "                # since n1 is an igraph vertex object, we need to extract the id\n",
    "                n1_index = n1.index\n",
    "                if n2 != n1_index: \n",
    "                    a = min(n2, n1_index)\n",
    "                    b = max(n2, n1_index)\n",
    "                    all_potential_recommendations.add((a,b))\n",
    "                \n",
    "    return list(set(all_potential_recommendations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get nodes at distance 2 for future prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get nodes at distance 2 in test set\n",
    "dist_2 = find_nodes_at_distance_2(g)\n",
    "test_nodes = [(u,v) for u, v in dist_2 if (u in test_idxs) and (v in test_idxs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with ground truth\n",
    "test_list = []\n",
    "for u, v in test_nodes: \n",
    "    if (u, v) in ground_truth: test_list.append((u,v,1))\n",
    "    else: test_list.append((u,v,0))\n",
    "        \n",
    "test_df = pd.DataFrame(test_list, columns = [\"u\", \"v\", \"ground_truth\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adamic-Adar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ADA(u,v, graph):\n",
    "    \"\"\"\n",
    "    compute adamic-adar from scratch\n",
    "    \"\"\"\n",
    "    # set of neighbors of u\n",
    "    outlinks_from_u = set(graph.neighbors(u))\n",
    "    # set of neighbors of v\n",
    "    inlinks_to_v = set(graph.neighbors(v))\n",
    "    \n",
    "    # set Z of neighbors of both\n",
    "    bridges = outlinks_from_u.intersection(inlinks_to_v)\n",
    "    \n",
    "    # degree of nodes in set Z\n",
    "    deg_ = [graph.degree(node) for node in bridges]\n",
    "    \n",
    "    # computing the reciprocal in log-scale\n",
    "    out = [1./np.log2(dd+1) for dd in deg_]\n",
    "\n",
    "    return sum(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ADA = []\n",
    "# Predictions\n",
    "for i, row in test_df.iterrows():\n",
    "    pred = compute_ADA(int(row[\"u\"]), int(row[\"v\"]), g)\n",
    "    pred_ADA.append(pred)\n",
    "test_df[\"ADA\"] = pred_ADA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"Red\">\n",
    "    \n",
    "    \n",
    "**CALCULAR nDCG**\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the adjacency matrix data\n",
    "M = g.get_adjacency().data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = csr_matrix(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a70fec5959f4ae4bd4d67fefe8d8ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the model ALS\n",
    "model = implicit.als.AlternatingLeastSquares(factors=10, calculate_training_loss=True,  iterations=5)\n",
    "\n",
    "# Train the model on a sparse matrix of item/user/confidence weights\n",
    "model.fit(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ALS(testset, model):\n",
    "    \"\"\"\n",
    "    predict for a list of observations the score for adding/removing a link\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize the empty list\n",
    "    all_predictions = []\n",
    "\n",
    "    # scroll the obs\n",
    "    for n1, n2, w in testset:\n",
    "        \n",
    "        # take here the low-dimensional vectors returned by the matrix factorization\n",
    "        \n",
    "        array_n1 = model.user_factors[n1, :]\n",
    "        array_n2 = model.item_factors[n2, :]\n",
    "\n",
    "        # multiplying these vectors we generate an approximation for the edge score\n",
    "        one_p = np.dot(array_n1, array_n2)\n",
    "\n",
    "        all_predictions.append(one_p)\n",
    "        \n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the predictions\n",
    "all_predictions = predict_ALS(test_df[[\"u\", \"v\", \"ground_truth\"]].values, model)\n",
    "\n",
    "# add predictions to df\n",
    "test_df[\"ALS\"] = all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>ADA</th>\n",
       "      <th>ALS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>371</td>\n",
       "      <td>9935</td>\n",
       "      <td>0</td>\n",
       "      <td>0.095358</td>\n",
       "      <td>-0.000495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2260</td>\n",
       "      <td>6001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.095358</td>\n",
       "      <td>-0.000151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4321</td>\n",
       "      <td>14803</td>\n",
       "      <td>0</td>\n",
       "      <td>0.095358</td>\n",
       "      <td>0.010087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2901</td>\n",
       "      <td>3619</td>\n",
       "      <td>0</td>\n",
       "      <td>0.095358</td>\n",
       "      <td>-0.000478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>480</td>\n",
       "      <td>16009</td>\n",
       "      <td>0</td>\n",
       "      <td>0.095358</td>\n",
       "      <td>-0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32383</th>\n",
       "      <td>2142</td>\n",
       "      <td>13032</td>\n",
       "      <td>0</td>\n",
       "      <td>0.113583</td>\n",
       "      <td>0.000629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32384</th>\n",
       "      <td>112</td>\n",
       "      <td>5267</td>\n",
       "      <td>0</td>\n",
       "      <td>0.127667</td>\n",
       "      <td>0.000258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32385</th>\n",
       "      <td>553</td>\n",
       "      <td>14304</td>\n",
       "      <td>0</td>\n",
       "      <td>0.095358</td>\n",
       "      <td>0.000457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32386</th>\n",
       "      <td>2132</td>\n",
       "      <td>7591</td>\n",
       "      <td>0</td>\n",
       "      <td>0.280150</td>\n",
       "      <td>0.086707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32387</th>\n",
       "      <td>5431</td>\n",
       "      <td>8330</td>\n",
       "      <td>0</td>\n",
       "      <td>0.095358</td>\n",
       "      <td>-0.000077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32388 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          u      v  ground_truth       ADA       ALS\n",
       "0       371   9935             0  0.095358 -0.000495\n",
       "1      2260   6001             0  0.095358 -0.000151\n",
       "2      4321  14803             0  0.095358  0.010087\n",
       "3      2901   3619             0  0.095358 -0.000478\n",
       "4       480  16009             0  0.095358 -0.000072\n",
       "...     ...    ...           ...       ...       ...\n",
       "32383  2142  13032             0  0.113583  0.000629\n",
       "32384   112   5267             0  0.127667  0.000258\n",
       "32385   553  14304             0  0.095358  0.000457\n",
       "32386  2132   7591             0  0.280150  0.086707\n",
       "32387  5431   8330             0  0.095358 -0.000077\n",
       "\n",
       "[32388 rows x 5 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PageRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "delete vertices from g --> all vertices except the ones in test_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_graph = deepcopy(g)\n",
    "new_graph.delete_vertices([i for i in range(len(ids_mapping)) if i not in test_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppage_rank(graph, test_df):\n",
    "    # here we need also the argument vid, which corresponds to a node-id\n",
    "    probab = []\n",
    "    for u, v in test_df[[\"u\", \"v\"]].values: \n",
    "        probab.append(graph.personalized_pagerank(reset_vertices=u)[v])\n",
    "    return probab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"PPageRank\"] = ppage_rank(g, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topk (scores, column, topk)\n",
    "    scores = scores.sort_values(by=column, ascending = False)\n",
    "    return scores[:topk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
