{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, '../search-engine')\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "from igraph import *\n",
    "import implicit\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import ndcg_score\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB3 - Link analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data \n",
    "Read tweets from data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_tweets(None, None, mode = \"read\", data_directory = '../data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Graph creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph will be created using `igraph` library. The graph will contain only users that have retweeted tweets from other users that also appear in the data collection. Main characteristics are: \n",
    "- Direted graph: A -> B means user A retweeted a tweet from user B. \n",
    "- Nodes: Users\n",
    "- Edges: Retweets. Not weighted graph: meaning that, if user A retweeted three times user B, the number of retweets will not be represented in the graph, only the connection between users. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: `igraph` graphs do not contain labels for nodes, therefore, there needs to be a mapping between users' id and the id of the node in the graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping between user id and node id in the graph.\n",
    "ids_mapping = {}\n",
    "counter = 0\n",
    "for tweet in data:\n",
    "    if \"retweeted_status\" in tweet.keys():\n",
    "        if tweet[\"user\"][\"id\"] not in ids_mapping.keys():\n",
    "            ids_mapping[tweet[\"user\"][\"id\"]] = counter            \n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping betweet node id and user name\n",
    "user_names_mapping = {}\n",
    "for tweet in data:\n",
    "    if \"retweeted_status\" in tweet.keys():\n",
    "        user_names_mapping[ids_mapping[tweet[\"user\"][\"id\"]]] = tweet[\"user\"][\"name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of a dictionary containing as key the node id of the users that retweeted at least a tweet and as value, the node id of the users that wrote the original tweets.\n",
    "\n",
    "An additional dictionary with the hashtags of each tweet (having as key the node id of the users) that will be needed later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of a dictionaries\n",
    "retweets = {}\n",
    "hashtags = {} \n",
    "\n",
    "for i, tweet in enumerate(data): \n",
    "    try: \n",
    "        # Store relations between users that have retweeted at least one tweet\n",
    "        id2 = ids_mapping[tweet[\"retweeted_status\"][\"user\"][\"id\"]]        \n",
    "        id1 = ids_mapping[tweet[\"user\"][\"id\"]]\n",
    "        try: retweets[id1].append(id2)\n",
    "        except: retweets[id1] = [id2]\n",
    "        \n",
    "        if id1 not in hashtags.keys(): hashtags[id1] = []\n",
    "        if id2 not in hashtags.keys(): hashtags[id2] = []\n",
    "        \n",
    "        # Store hashtags list for each user for personalized score\n",
    "        for hashtag in tweet[\"entities\"][\"hashtags\"]:\n",
    "            hashtags[id1].append(hashtag[\"text\"])\n",
    "            hashtags[id2].append(hashtag[\"text\"])\n",
    "    except: \n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform hashtags dictionary into a list for the creation of the graph\n",
    "edgelist = []\n",
    "for node in retweets:\n",
    "    for i in retweets[node]:\n",
    "        edgelist.append((node, i))\n",
    "        \n",
    "edgelist = list(set(edgelist)) # Remove duplicated links (since the graph is not weighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of the graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Graph(n = len(ids_mapping))\n",
    "g.add_edges(edgelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Networks based predictions\n",
    "Prepare the dataset: split graph into train and test, 80-20% respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.2       # fraction of edges to select as test-set\n",
    "N = len(g.es) # graphsize\n",
    "\n",
    "all_idxs = range(N) # idxs of all the edges\n",
    "\n",
    "# sample randomly test nodes \n",
    "np.random.seed(0)\n",
    "test_idxs = np.random.choice(a=all_idxs, size=int(p*N),replace=False)\n",
    "\n",
    "# Create the train-set and ground truth for the test set \n",
    "ground_truth = set() # links between nodes of the test set\n",
    "trainset = set()     # links between nodes of the train set\n",
    "\n",
    "for idx, one_edge in enumerate(g.es):    \n",
    "    n1 = one_edge.source\n",
    "    n2 = one_edge.target\n",
    "\n",
    "    if idx in test_idxs:\n",
    "        ground_truth.add((n1, n2))\n",
    "    else:\n",
    "        trainset.add((n1, n2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance 2 \n",
    "The goal of this part of the project is to predict the probability of having an edge for those users at distance 2. \n",
    "\n",
    "Therefore, we need to consider those nodes that are at distance 2, to predict if there's a node between them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select nodes at distance 2 (they can also may be at distance 1)\n",
    "def find_nodes_at_distance_2(graph):\n",
    "    all_potential_recommendations = set()\n",
    "    \n",
    "    for n1 in graph.vs:\n",
    "        # all the nodes at distance 1 and distance 2\n",
    "        nodes_at_most_distant_2 = set(graph.neighborhood(n1, order = 2))\n",
    "            \n",
    "        if len(nodes_at_most_distant_2) > 0:\n",
    "            for n2 in nodes_at_most_distant_2: \n",
    "                n1_index = n1.index\n",
    "                if n2 != n1_index: \n",
    "                    a = min(n2, n1_index)\n",
    "                    b = max(n2, n1_index)\n",
    "                    all_potential_recommendations.add((a,b))\n",
    "    return list(set(all_potential_recommendations))\n",
    "\n",
    "# Get nodes at distance 2 in test set\n",
    "dist_2 = find_nodes_at_distance_2(g)\n",
    "test_nodes = [(u,v) for u, v in dist_2 if (u in test_idxs) and (v in test_idxs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe containing the ground truth for the test set. 0 means they have no direct link, while 1 means they are connected. \n",
    "\n",
    "NOTE: there is a path of length at most 2 between the pairs of nodes we are considering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5951</td>\n",
       "      <td>13583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3908</td>\n",
       "      <td>10085</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>325</td>\n",
       "      <td>8039</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1156</td>\n",
       "      <td>6255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14735</td>\n",
       "      <td>14835</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       u      v  ground_truth\n",
       "0   5951  13583             0\n",
       "1   3908  10085             0\n",
       "2    325   8039             0\n",
       "3   1156   6255             0\n",
       "4  14735  14835             0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe with ground truth\n",
    "test_list = []\n",
    "for u, v in test_nodes: \n",
    "    if (u, v) in ground_truth: test_list.append((u,v,1))\n",
    "    else: test_list.append((u,v,0))\n",
    "        \n",
    "test_df = pd.DataFrame(test_list, columns = [\"u\", \"v\", \"ground_truth\"])\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General statistics on train and test sets \n",
    "\n",
    "Statistics considered: \n",
    "- `number of nodes`\n",
    "- `number of edges`\n",
    "- `top-10 inlink users`: number of input links for each node \n",
    "- `top-10 pagerank users`: it defines a probability distribution over all the nodes in the graph. A score/probability assigned to each node indicates the importance of the single node, taking into account both local and global structure of the graph (link)\n",
    "- `top-10 colseness users` and `total closeness centrality`: it is a measure of centrality in a network, calculated as the reciprocal of the sum of the length o the shortest paths between the node and all other nodes in the graph. Thus, the more central a node is, the closer it is to all other nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping to users names\n",
    "general_df = pd.DataFrame(edgelist,  columns = [\"Retweeter\", \"Author\"])\n",
    "general_df = general_df.replace(user_names_mapping)\n",
    "\n",
    "train_df = pd.DataFrame(trainset, columns = [\"Retweeter\", \"Author\"])\n",
    "train_df_names = train_df.replace(user_names_mapping)\n",
    "\n",
    "test_df_names = test_df[test_df[\"ground_truth\"] != 0][[\"u\", \"v\"]].replace(user_names_mapping)\n",
    "\n",
    "ground_df = pd.DataFrame(ground_truth, columns = [\"Retweeter\", \"Author\"])\n",
    "ground_df = ground_df.replace(user_names_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "# Create graphs with networkx\n",
    "general_G = nx.DiGraph()\n",
    "general_G.add_edges_from(general_df.values)\n",
    "\n",
    "train_G = nx.DiGraph()\n",
    "train_G.add_edges_from(train_df_names.values)\n",
    "\n",
    "test_G = nx.DiGraph()\n",
    "test_G.add_edges_from(test_df_names.values)\n",
    "test_G.add_nodes_from(ground_df[\"Retweeter\"].values)\n",
    "test_G.add_nodes_from(ground_df[\"Author\"].values)\n",
    "\n",
    "ground_G = nx.DiGraph()\n",
    "ground_G.add_edges_from(ground_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General graph contains\n",
      " - 12270 users\n",
      " - 18552 retweet links\n",
      "\n",
      "Training graph contains\n",
      " - 10485 users\n",
      " - 14709 retweet links\n",
      "\n",
      "Testing graph contains\n",
      " - 3781 users\n",
      " - 76 retweet links\n",
      "\n",
      "Testing ground truth graph contains\n",
      " - 3781 users\n",
      " - 3706 retweet links\n"
     ]
    }
   ],
   "source": [
    "# Get number of nodes and links\n",
    "print(\"General graph contains\\n - {} users\\n - {} retweet links\".format(len(general_G.nodes), len(general_G.edges)))\n",
    "print(\"\\nTraining graph contains\\n - {} users\\n - {} retweet links\".format(len(train_G.nodes), len(train_G.edges)))\n",
    "print(\"\\nTesting graph contains\\n - {} users\\n - {} retweet links\".format(len(test_G.nodes), len(test_G.edges)))\n",
    "print(\"\\nTesting ground truth graph contains\\n - {} users\\n - {} retweet links\".format(len(ground_G.nodes), len(ground_G.edges)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-10 inlinks of the general graph\n",
      "('LORI HENDRY', 1417)\n",
      "('Dr. Kelli Ward 🇺🇸', 691)\n",
      "('Aaron Rupar', 467)\n",
      "('❌🇺🇸Steve🇺🇸🇺🇸America First🇺🇸🇮🇹MAGA🇺🇸KAG', 463)\n",
      "('Machiavelli', 444)\n",
      "('DeplorableArmyBrat', 276)\n",
      "('Ryan Pence ⭐⭐⭐', 234)\n",
      "('John Harwood', 226)\n",
      "('Citizens for Ethics', 224)\n",
      "('Katie Johnson2020', 207)\n",
      "\n",
      "Top-10 inlinks of training graph\n",
      "('LORI HENDRY', 996)\n",
      "('Dr. Kelli Ward 🇺🇸', 306)\n",
      "('❌🇺🇸Steve🇺🇸🇺🇸America First🇺🇸🇮🇹MAGA🇺🇸KAG', 211)\n",
      "('Aaron Rupar', 189)\n",
      "('Machiavelli', 174)\n",
      "('Ryan Pence ⭐⭐⭐', 154)\n",
      "('DeplorableArmyBrat', 153)\n",
      "('Citizens for Ethics', 146)\n",
      "('John Harwood', 140)\n",
      "('Jon Cooper 🇺🇸', 118)\n",
      "\n",
      "Top-10 inlinks of testing graph\n",
      "('❌🇺🇸Steve🇺🇸🇺🇸America First🇺🇸🇮🇹MAGA🇺🇸KAG', 11)\n",
      "('Machiavelli', 10)\n",
      "('Aaron Rupar', 7)\n",
      "('sakshi🌸', 2)\n",
      "('𝒜𝒩𝒿𝒶𝒶𝓃', 2)\n",
      "('LivePDDave 🇺🇸 🚨 🥊', 2)\n",
      "('Pigzzyy', 2)\n",
      "('Speak out omaha', 2)\n",
      "('Mike Engleman⭐⭐⭐', 2)\n",
      "('#CompassionateRelease4Reality', 1)\n",
      "\n",
      "Top-10 inlinks of testing ground trugh graph\n",
      "('LORI HENDRY', 224)\n",
      "('Dr. Kelli Ward 🇺🇸', 81)\n",
      "('❌🇺🇸Steve🇺🇸🇺🇸America First🇺🇸🇮🇹MAGA🇺🇸KAG', 62)\n",
      "('Ryan Pence ⭐⭐⭐', 46)\n",
      "('Machiavelli', 45)\n",
      "('Aaron Rupar', 39)\n",
      "('John Harwood', 38)\n",
      "('Citizens for Ethics', 38)\n",
      "('Jason Miller', 37)\n",
      "('PlayTheTrumpCard ⚡️ Legal Votes Only Please', 29)\n"
     ]
    }
   ],
   "source": [
    "# Get top-10 inlinks\n",
    "print(\"\\nTop-10 inlinks of the general graph\")\n",
    "for row in sorted(general_G.in_degree(), key=lambda x: x[1], reverse=True)[:10]: print(row)\n",
    "\n",
    "print(\"\\nTop-10 inlinks of training graph\")\n",
    "for row in sorted(train_G.in_degree(), key=lambda x: x[1], reverse=True)[:10]: print(row)\n",
    "\n",
    "print(\"\\nTop-10 inlinks of testing graph\")\n",
    "for row in sorted(test_G.in_degree(), key=lambda x: x[1], reverse=True)[:10]: print(row)\n",
    "\n",
    "print(\"\\nTop-10 inlinks of testing ground trugh graph\")\n",
    "for row in sorted(ground_G.in_degree(), key=lambda x: x[1], reverse=True)[:10]: print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-10 pagerank of the general graph\n",
      "('LORI HENDRY', 0.10166842783178236)\n",
      "('PlayTheTrumpCard ⚡️ Legal Votes Only Please', 0.030645838388244674)\n",
      "('Ryan Pence ⭐⭐⭐', 0.030153812353229552)\n",
      "('Michael Guy', 0.028978706097937325)\n",
      "('John Harwood', 0.020153132846440026)\n",
      "('Citizens for Ethics', 0.018765167825236947)\n",
      "('LivePDDave 🇺🇸 🚨 🥊', 0.01654695811855514)\n",
      "('Jon Cooper 🇺🇸', 0.015881267864422927)\n",
      "('(((DeanObeidallah)))', 0.01524893854881681)\n",
      "('Dr. Kelli Ward 🇺🇸', 0.014380354249883619)\n",
      "\n",
      "Top-10 pagerank of training graph\n",
      "('LORI HENDRY', 0.033385958877422434)\n",
      "('Dr. Kelli Ward 🇺🇸', 0.008840814382755736)\n",
      "('Ryan Pence ⭐⭐⭐', 0.00534753234688879)\n",
      "('Aaron Rupar', 0.005237079053696349)\n",
      "('John Harwood', 0.005005205827125815)\n",
      "('❌🇺🇸Steve🇺🇸🇺🇸America First🇺🇸🇮🇹MAGA🇺🇸KAG', 0.004877377973597925)\n",
      "('Citizens for Ethics', 0.004501607235068948)\n",
      "('Machiavelli', 0.004221274018313596)\n",
      "('DeplorableArmyBrat', 0.00406718578955062)\n",
      "('Jason Miller', 0.0037276289435704854)\n",
      "\n",
      "Top-10 pagerank of testing graph\n",
      "('❌🇺🇸Steve🇺🇸🇺🇸America First🇺🇸🇮🇹MAGA🇺🇸KAG', 0.002682144864281137)\n",
      "('Machiavelli', 0.0023517409964042215)\n",
      "('🇺🇲🇺🇸DeplorablePnewiz🇺🇲🇺🇲', 0.002267844418084069)\n",
      "('Aaron Rupar', 0.0018010678832760284)\n",
      "('⚖⏰Tick, Tock...', 0.0014047026349044494)\n",
      "('tom greene', 0.0014047026349044494)\n",
      "('Mike Engleman⭐⭐⭐', 0.0007778388245324984)\n",
      "('LivePDDave 🇺🇸 🚨 🥊', 0.0006997216570196418)\n",
      "('𝒜𝒩𝒿𝒶𝒶𝓃', 0.0006837129294632507)\n",
      "('Karen', 0.0006677042019068597)\n",
      "\n",
      "Top-10 pagerank of testing ground trugh graph\n",
      "('LORI HENDRY', 0.025951302171436343)\n",
      "('Dr. Kelli Ward 🇺🇸', 0.009131518550709058)\n",
      "('Ryan Pence ⭐⭐⭐', 0.005818269827465901)\n",
      "('❌🇺🇸Steve🇺🇸🇺🇸America First🇺🇸🇮🇹MAGA🇺🇸KAG', 0.005738049351304703)\n",
      "('John Harwood', 0.004623459270173484)\n",
      "('Citizens for Ethics', 0.004582340259900586)\n",
      "('Aaron Rupar', 0.004508457744776157)\n",
      "('Jason Miller', 0.004458080649748338)\n",
      "('Machiavelli', 0.004364028795514124)\n",
      "('Tiyas❤', 0.004033099969866081)\n"
     ]
    }
   ],
   "source": [
    "# Get top-10 pagerank users\n",
    "print(\"\\nTop-10 pagerank of the general graph\")\n",
    "for row in sorted(nx.pagerank(general_G).items(), key=lambda x: x[1], reverse=True)[:10]: print(row)\n",
    "\n",
    "print(\"\\nTop-10 pagerank of training graph\")\n",
    "for row in sorted(nx.pagerank(train_G).items(), key=lambda x: x[1], reverse=True)[:10]: print(row)\n",
    "\n",
    "print(\"\\nTop-10 pagerank of testing graph\")\n",
    "for row in sorted(nx.pagerank(test_G).items(), key=lambda x: x[1], reverse=True)[:10]: print(row)\n",
    "\n",
    "print(\"\\nTop-10 pagerank of testing ground trugh graph\")\n",
    "for row in sorted(nx.pagerank(ground_G).items(), key=lambda x: x[1], reverse=True)[:10]: print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closeness centrality of general graph: 4.319447339126578\n",
      "Closeness centrality of training graph: 117.28396749144667\n",
      "Closeness centrality of testing graph: 0.025374861699913473\n",
      "Closeness centrality of ground truth graph: 5.122661381085046\n"
     ]
    }
   ],
   "source": [
    "# General closeness centrality\n",
    "count = 0\n",
    "general_centrality = nx.closeness_centrality(general_G)\n",
    "for elem in general_centrality: count += general_centrality[elem]\n",
    "print(\"Closeness centrality of general graph: {}\".format(count))\n",
    "\n",
    "count = 0\n",
    "train_centrality = nx.closeness_centrality(train_G)\n",
    "for elem in train_centrality: count += train_centrality[elem]\n",
    "print(\"Closeness centrality of training graph: {}\".format(count))\n",
    "\n",
    "count = 0\n",
    "test_centrality = nx.closeness_centrality(test_G)\n",
    "for elem in test_centrality: count += test_centrality[elem]\n",
    "print(\"Closeness centrality of testing graph: {}\".format(count))\n",
    "\n",
    "count = 0\n",
    "ground_centrality = nx.closeness_centrality(ground_G)\n",
    "for elem in ground_centrality: count += ground_centrality[elem]\n",
    "print(\"Closeness centrality of ground truth graph: {}\".format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-10 closeness centrality of the general graph\n",
      "('LORI HENDRY', 0.1237464910795504)\n",
      "('PlayTheTrumpCard ⚡️ Legal Votes Only Please', 0.09859107503577307)\n",
      "('Michael Guy', 0.08729944763851358)\n",
      "('Dr. Kelli Ward 🇺🇸', 0.08413130367808799)\n",
      "('Machiavelli', 0.06009053100161735)\n",
      "('DeplorableArmyBrat', 0.05997625966192418)\n",
      "('❌🇺🇸Steve🇺🇸🇺🇸America First🇺🇸🇮🇹MAGA🇺🇸KAG', 0.05954992073747574)\n",
      "('Ryan Pence ⭐⭐⭐', 0.05357710798276674)\n",
      "('VP Elect Storm Nicole', 0.05253837838076708)\n",
      "('Sheri - Stop the Sloppy Steal!', 0.04722568252603301)\n",
      "\n",
      "Top-10 closeness centrality of training graph\n",
      "('LORI HENDRY', 0.11323693857528437)\n",
      "('Danny Meilleur', 0.0888863347655578)\n",
      "('Sue', 0.08480430734020797)\n",
      "('MJ', 0.08404947269205874)\n",
      "('Skip', 0.08375471142873275)\n",
      "('Sandi', 0.08279679337089903)\n",
      "('JWS - Parler- @JWSNMNJ hit me there.', 0.08256384638220617)\n",
      "('Hanakuli', 0.08223192622611299)\n",
      "('Mike', 0.08223002792945346)\n",
      "('Robin Lynne Yates', 0.08221938660903651)\n",
      "\n",
      "Top-10 closeness centrality of testing graph\n",
      "('❌🇺🇸Steve🇺🇸🇺🇸America First🇺🇸🇮🇹MAGA🇺🇸KAG', 0.00291005291005291)\n",
      "('Machiavelli', 0.0026455026455026454)\n",
      "('Aaron Rupar', 0.001851851851851852)\n",
      "('⚖⏰Tick, Tock...', 0.0016563146997929607)\n",
      "('tom greene', 0.0016563146997929607)\n",
      "('🇺🇲🇺🇸DeplorablePnewiz🇺🇲🇺🇲', 0.0015243134290753339)\n",
      "('Mike Engleman⭐⭐⭐', 0.0007054673721340388)\n",
      "('sakshi🌸', 0.0005952380952380953)\n",
      "('𝒜𝒩𝒿𝒶𝒶𝓃', 0.0005952380952380953)\n",
      "('LivePDDave 🇺🇸 🚨 🥊', 0.0005291005291005291)\n",
      "\n",
      "Top-10 closeness centrality of testing ground trugh graph\n",
      "('LORI HENDRY', 0.056574781151052335)\n",
      "('Rudi', 0.044636844636844634)\n",
      "('❌Christina❌', 0.03824074074074074)\n",
      "('Keith', 0.037327501509784304)\n",
      "('DM', 0.037327501509784304)\n",
      "('Mary thomason', 0.03717596539420921)\n",
      "('Loving Life', 0.03717596539420921)\n",
      "('Melody🇺🇸🕊🌎', 0.03717596539420921)\n",
      "('George Kaplan', 0.03717596539420921)\n",
      "('Alistair Armstrong', 0.03717596539420921)\n"
     ]
    }
   ],
   "source": [
    "# Get top-10 closeness users\n",
    "print(\"\\nTop-10 closeness centrality of the general graph\")\n",
    "for row in sorted(general_centrality.items(), key=lambda x: x[1], reverse=True)[:10]: print(row)\n",
    "\n",
    "print(\"\\nTop-10 closeness centrality of training graph\")\n",
    "for row in sorted(train_centrality.items(), key=lambda x: x[1], reverse=True)[:10]: print(row)\n",
    "\n",
    "print(\"\\nTop-10 closeness centrality of testing graph\")\n",
    "for row in sorted(test_centrality.items(), key=lambda x: x[1], reverse=True)[:10]: print(row)\n",
    "\n",
    "print(\"\\nTop-10 closeness centrality of testing ground trugh graph\")\n",
    "for row in sorted(ground_centrality.items(), key=lambda x: x[1], reverse=True)[:10]: print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Adamic-Adar (ADA)\n",
    "In this section we will use Adamic-Adar to compute the probability of having a direct link between all nodes that are at most at distance 2. \n",
    "This algorithm does not require a training set, it can be directly applied to the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ADA(u,v, graph):\n",
    "    # set of neighbors of u\n",
    "    outlinks_from_u = set(graph.neighbors(u))\n",
    "    # set of neighbors of v\n",
    "    inlinks_to_v = set(graph.neighbors(v))\n",
    "    \n",
    "    # set Z of neighbors of both\n",
    "    bridges = outlinks_from_u.intersection(inlinks_to_v)\n",
    "    \n",
    "    # degree of nodes in set Z\n",
    "    deg_ = [graph.degree(node) for node in bridges]\n",
    "    \n",
    "    # computing the reciprocal in log-scale\n",
    "    out = [1./np.log2(dd+1) for dd in deg_]\n",
    "\n",
    "    return sum(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>ADA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5951</td>\n",
       "      <td>13583</td>\n",
       "      <td>0</td>\n",
       "      <td>0.095358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3908</td>\n",
       "      <td>10085</td>\n",
       "      <td>0</td>\n",
       "      <td>0.095358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>325</td>\n",
       "      <td>8039</td>\n",
       "      <td>0</td>\n",
       "      <td>0.113583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1156</td>\n",
       "      <td>6255</td>\n",
       "      <td>0</td>\n",
       "      <td>0.172195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14735</td>\n",
       "      <td>14835</td>\n",
       "      <td>0</td>\n",
       "      <td>0.127667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       u      v  ground_truth       ADA\n",
       "0   5951  13583             0  0.095358\n",
       "1   3908  10085             0  0.095358\n",
       "2    325   8039             0  0.113583\n",
       "3   1156   6255             0  0.172195\n",
       "4  14735  14835             0  0.127667"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the probability\n",
    "pred_ADA = []\n",
    "# Predictions\n",
    "for i, row in test_df.iterrows():\n",
    "    pred = compute_ADA(int(row[\"u\"]), int(row[\"v\"]), g)\n",
    "    pred_ADA.append(pred)\n",
    "    \n",
    "test_df[\"ADA\"] = pred_ADA # Append probabilities to the dataframe\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Alternating Least Squares (ALS)\n",
    "This algorithm has been tested using `implicit` libary. It requires an adjacency matrix (a sparse one). And the approximated predictions are obtained from the dot product of the low-dimensionality vectors obtained from the matrix factorization performed by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the adjacency matrix data\n",
    "M = g.get_adjacency().data\n",
    "M = csr_matrix(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd16dac9733f47d5bf00475919f60a6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Declare the model ALS\n",
    "model = implicit.als.AlternatingLeastSquares(factors=10, calculate_training_loss=True, iterations=5)\n",
    "\n",
    "# Train the model on a sparse matrix\n",
    "model.fit(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link prediction\n",
    "def predict_ALS(testset, model):\n",
    "    all_predictions = []\n",
    "    for n1, n2, w in testset:\n",
    "        # take low-dimensional vectors returned by the matrix factorization\n",
    "        array_n1 = model.user_factors[n1, :]\n",
    "        array_n2 = model.item_factors[n2, :]\n",
    "\n",
    "        # approximation for the edge score\n",
    "        one_p = np.dot(array_n1, array_n2)\n",
    "        all_predictions.append(one_p)\n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "all_predictions = predict_ALS(test_df[[\"u\", \"v\", \"ground_truth\"]].values, model)\n",
    "\n",
    "test_df[\"ALS\"] = all_predictions # Append predictions to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>ADA</th>\n",
       "      <th>ALS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5951</td>\n",
       "      <td>13583</td>\n",
       "      <td>0</td>\n",
       "      <td>0.095358</td>\n",
       "      <td>-0.000070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3908</td>\n",
       "      <td>10085</td>\n",
       "      <td>0</td>\n",
       "      <td>0.095358</td>\n",
       "      <td>-0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>325</td>\n",
       "      <td>8039</td>\n",
       "      <td>0</td>\n",
       "      <td>0.113583</td>\n",
       "      <td>0.012325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1156</td>\n",
       "      <td>6255</td>\n",
       "      <td>0</td>\n",
       "      <td>0.172195</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14735</td>\n",
       "      <td>14835</td>\n",
       "      <td>0</td>\n",
       "      <td>0.127667</td>\n",
       "      <td>-0.000040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       u      v  ground_truth       ADA       ALS\n",
       "0   5951  13583             0  0.095358 -0.000070\n",
       "1   3908  10085             0  0.095358 -0.000061\n",
       "2    325   8039             0  0.113583  0.012325\n",
       "3   1156   6255             0  0.172195  0.000042\n",
       "4  14735  14835             0  0.127667 -0.000040"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Personalized PageRank (PPageRank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library `igraph` has implemented a personalized page rank computation. In personalized page rank, the starting node needs to be specified.\n",
    "\n",
    "\n",
    "For each pair of nodes (A, B) in the graph, the probability of having a link between them is computed by computing the PPageRank starting from A and getting the probability for B. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since PPageRank is performed given a graph, all edges from outside the testset should\n",
    "# be dropeed. \n",
    "new_graph = deepcopy(g)\n",
    "new_graph.delete_vertices([i for i in range(len(ids_mapping)) if i not in test_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppage_rank(graph, test_df):\n",
    "    probab = []\n",
    "    # For each pair of nodes, compute their probability.\n",
    "    for u, v in test_df[[\"u\", \"v\"]].values: \n",
    "        probab.append(graph.personalized_pagerank(reset_vertices=u)[v])\n",
    "    return probab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"PPageRank\"] = ppage_rank(g, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>ADA</th>\n",
       "      <th>ALS</th>\n",
       "      <th>PPageRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5951</td>\n",
       "      <td>13583</td>\n",
       "      <td>0</td>\n",
       "      <td>0.095358</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>0.000097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3908</td>\n",
       "      <td>10085</td>\n",
       "      <td>0</td>\n",
       "      <td>0.095358</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>0.000210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>325</td>\n",
       "      <td>8039</td>\n",
       "      <td>0</td>\n",
       "      <td>0.113583</td>\n",
       "      <td>0.012325</td>\n",
       "      <td>0.000453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1156</td>\n",
       "      <td>6255</td>\n",
       "      <td>0</td>\n",
       "      <td>0.172195</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.004614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14735</td>\n",
       "      <td>14835</td>\n",
       "      <td>0</td>\n",
       "      <td>0.127667</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>0.000632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30969</th>\n",
       "      <td>2306</td>\n",
       "      <td>8998</td>\n",
       "      <td>0</td>\n",
       "      <td>0.095358</td>\n",
       "      <td>-0.000092</td>\n",
       "      <td>0.000188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30970</th>\n",
       "      <td>4288</td>\n",
       "      <td>5111</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140676</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.000501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30971</th>\n",
       "      <td>521</td>\n",
       "      <td>9591</td>\n",
       "      <td>0</td>\n",
       "      <td>0.129401</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30972</th>\n",
       "      <td>4235</td>\n",
       "      <td>12262</td>\n",
       "      <td>0</td>\n",
       "      <td>0.095358</td>\n",
       "      <td>-0.000215</td>\n",
       "      <td>0.000062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30973</th>\n",
       "      <td>2049</td>\n",
       "      <td>13435</td>\n",
       "      <td>0</td>\n",
       "      <td>0.095358</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>0.000164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30974 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           u      v  ground_truth       ADA       ALS  PPageRank\n",
       "0       5951  13583             0  0.095358 -0.000070   0.000097\n",
       "1       3908  10085             0  0.095358 -0.000061   0.000210\n",
       "2        325   8039             0  0.113583  0.012325   0.000453\n",
       "3       1156   6255             0  0.172195  0.000042   0.004614\n",
       "4      14735  14835             0  0.127667 -0.000040   0.000632\n",
       "...      ...    ...           ...       ...       ...        ...\n",
       "30969   2306   8998             0  0.095358 -0.000092   0.000188\n",
       "30970   4288   5111             0  0.140676  0.000436   0.000501\n",
       "30971    521   9591             0  0.129401  0.000195   0.000456\n",
       "30972   4235  12262             0  0.095358 -0.000215   0.000062\n",
       "30973   2049  13435             0  0.095358 -0.000051   0.000164\n",
       "\n",
       "[30974 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Personalized score\n",
    "**Main idea**\n",
    "\n",
    "Improve ADA algorithm by adding a partial score to the one returned by ADA algorithm. \n",
    "The partial score considers information from the texts: the hashtags that each user has used. By doing so, we can relate the users having into account their common interests. \n",
    "\n",
    "The dictionary contianing the hashtags used by each user has been created at the beginning of section 2. \n",
    "\n",
    "\n",
    "**Personalized score**\n",
    "\n",
    "\\begin{equation*} \\mathbf{diversity\\_score = ADA + \\lambda * partial\\_score} \\end{equation*}\n",
    "Where: \n",
    "\n",
    "- $\\lambda = 1/3 * max(ADA)$ regulating the impact on the score \n",
    "\n",
    "- $ partial\\_score = Jaccard(hashtags\\_userA, hashtags\\_userB)$\n",
    "\n",
    "By considering the Jaccard similarity between the sets of hashtags used by both users, we are selecting the keywords that the users themselves have selected to summarize the content they are posting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jaccard similarity\n",
    "def compute_Jaccard(u,v):\n",
    "    if len(set(u).union(set(v))) == 0:\n",
    "        return 0.0\n",
    "    return len(set(u).intersection(set(v)))/len(set(u).union(set(v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>ADA</th>\n",
       "      <th>ALS</th>\n",
       "      <th>PPageRank</th>\n",
       "      <th>Personalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5951</td>\n",
       "      <td>13583</td>\n",
       "      <td>0</td>\n",
       "      <td>0.095358</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.095358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3908</td>\n",
       "      <td>10085</td>\n",
       "      <td>0</td>\n",
       "      <td>0.095358</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.095358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>325</td>\n",
       "      <td>8039</td>\n",
       "      <td>0</td>\n",
       "      <td>0.113583</td>\n",
       "      <td>0.012325</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.113583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1156</td>\n",
       "      <td>6255</td>\n",
       "      <td>0</td>\n",
       "      <td>0.172195</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.004614</td>\n",
       "      <td>0.172195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14735</td>\n",
       "      <td>14835</td>\n",
       "      <td>0</td>\n",
       "      <td>0.127667</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.127667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       u      v  ground_truth       ADA       ALS  PPageRank  Personalized\n",
       "0   5951  13583             0  0.095358 -0.000070   0.000097      0.095358\n",
       "1   3908  10085             0  0.095358 -0.000061   0.000210      0.095358\n",
       "2    325   8039             0  0.113583  0.012325   0.000453      0.113583\n",
       "3   1156   6255             0  0.172195  0.000042   0.004614      0.172195\n",
       "4  14735  14835             0  0.127667 -0.000040   0.000632      0.127667"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personalized_score = []\n",
    "lamb = 1/3\n",
    "max_ADA = test_df[\"ADA\"].max()\n",
    "\n",
    "# Compute personalized score\n",
    "for i, row in test_df.iterrows():\n",
    "    pred = compute_Jaccard(hashtags[int(row[\"u\"])], hashtags[int(row[\"v\"])])\n",
    "    personalized_score.append(row[\"ADA\"] + lamb * max_ADA * pred)\n",
    "    \n",
    "# Add it to the test dataframe    \n",
    "test_df[\"Personalized\"] = personalized_score \n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predictions\n",
    "Top-10 predictions for each algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topk (scores, column, topk = 10):\n",
    "    scores = scores.sort_values(by=column, ascending = False)\n",
    "    return scores[:topk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Top-10 recommendations from ADA algoritm\n",
      "          u      v        ADA  ground_truth\n",
      "26804  9670  12512  13.543626             0\n",
      "22720  5539  12512   7.772859             0\n",
      "20160  1547   3420   7.477919             0\n",
      "29239   346   3420   7.012568             1\n",
      "23051   346   1547   6.853266             0\n",
      "\n",
      "\n",
      "Top-10 recommendations from ALS algoritm\n",
      "          u      v       ALS  ground_truth\n",
      "20160  1547   3420  1.169639             0\n",
      "8809    503  14583  1.144972             0\n",
      "29239   346   3420  1.132539             1\n",
      "5404   2359  12512  1.123251             0\n",
      "23051   346   1547  1.112424             0\n",
      "\n",
      "\n",
      "Top-10 recommendations from PPageRank algoritm\n",
      "           u      v  PPageRank  ground_truth\n",
      "25854   8790  14994   0.596491             0\n",
      "13216   8509  17594   0.459459             0\n",
      "17212   6023   7683   0.459459             0\n",
      "9504    9917  13967   0.459459             1\n",
      "1783   11396  17172   0.351615             1\n",
      "\n",
      "\n",
      "Top-10 recommendations from Personalized algoritm\n",
      "          u      v  Personalized  ground_truth\n",
      "26804  9670  12512     13.543626             0\n",
      "20160  1547   3420     11.992461             0\n",
      "29239   346   3420     11.527110             1\n",
      "23051   346   1547     11.367808             0\n",
      "16411    74   3420     10.637181             0\n"
     ]
    }
   ],
   "source": [
    "algorithms = [\"ADA\", \"ALS\", \"PPageRank\", \"Personalized\"]\n",
    "for algorithm in algorithms:\n",
    "    print(\"\\n\\nTop-5 recommendations from {} algoritm\".format(algorithm))\n",
    "    print(get_topk(test_df, algorithm)[[\"u\", \"v\", algorithm, \"ground_truth\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Top-10 recommendations from ADA algoritm\n",
      "                       u                                       v        ADA  \\\n",
      "26804        Machiavelli  ❌🇺🇸Steve🇺🇸🇺🇸America First🇺🇸🇮🇹MAGA🇺🇸KAG  13.543626   \n",
      "22720  LivePDDave 🇺🇸 🚨 🥊  ❌🇺🇸Steve🇺🇸🇺🇸America First🇺🇸🇮🇹MAGA🇺🇸KAG   7.772859   \n",
      "20160       𝙊𝙣 𝙖 𝙗𝙧𝙚𝙖𝙠 ♡                                 sakshi🌸   7.477919   \n",
      "29239          Mrs.Kabir                                 sakshi🌸   7.012568   \n",
      "23051          Mrs.Kabir                            𝙊𝙣 𝙖 𝙗𝙧𝙚𝙖𝙠 ♡   6.853266   \n",
      "\n",
      "       ground_truth  \n",
      "26804             0  \n",
      "22720             0  \n",
      "20160             0  \n",
      "29239             1  \n",
      "23051             0  \n",
      "\n",
      "\n",
      "Top-10 recommendations from ALS algoritm\n",
      "                        u                                       v       ALS  \\\n",
      "20160        𝙊𝙣 𝙖 𝙗𝙧𝙚𝙖𝙠 ♡                                 sakshi🌸  1.169639   \n",
      "8809              Tanis42                             Aaron Rupar  1.144972   \n",
      "29239           Mrs.Kabir                                 sakshi🌸  1.132539   \n",
      "5404   💥Lucy KRAKEN💥💥🐉🐲💥💥  ❌🇺🇸Steve🇺🇸🇺🇸America First🇺🇸🇮🇹MAGA🇺🇸KAG  1.123251   \n",
      "23051           Mrs.Kabir                            𝙊𝙣 𝙖 𝙗𝙧𝙚𝙖𝙠 ♡  1.112424   \n",
      "\n",
      "       ground_truth  \n",
      "20160             0  \n",
      "8809              0  \n",
      "29239             1  \n",
      "5404              0  \n",
      "23051             0  \n",
      "\n",
      "\n",
      "Top-10 recommendations from PPageRank algoritm\n",
      "                                        u                     v  PPageRank  \\\n",
      "25854                      Beverly Palmer     LunchHashtags 🌊💦💦   0.596491   \n",
      "13216              Octothorp (OctoKraken)       KAREN SCHREIBER   0.459459   \n",
      "17212                           Ambellina           Linda Brown   0.459459   \n",
      "9504   President-Elect Mike Rafone Droppe   Son of the Republic   0.459459   \n",
      "1783                    atin ◡̈ | semi ia  SOWON CELEBRATION!!!   0.351615   \n",
      "\n",
      "       ground_truth  \n",
      "25854             0  \n",
      "13216             0  \n",
      "17212             0  \n",
      "9504              1  \n",
      "1783              1  \n",
      "\n",
      "\n",
      "Top-10 recommendations from Personalized algoritm\n",
      "                  u                                       v  Personalized  \\\n",
      "26804   Machiavelli  ❌🇺🇸Steve🇺🇸🇺🇸America First🇺🇸🇮🇹MAGA🇺🇸KAG     13.543626   \n",
      "20160  𝙊𝙣 𝙖 𝙗𝙧𝙚𝙖𝙠 ♡                                 sakshi🌸     11.992461   \n",
      "29239     Mrs.Kabir                                 sakshi🌸     11.527110   \n",
      "23051     Mrs.Kabir                            𝙊𝙣 𝙖 𝙗𝙧𝙚𝙖𝙠 ♡     11.367808   \n",
      "16411         Laxmi                                 sakshi🌸     10.637181   \n",
      "\n",
      "       ground_truth  \n",
      "26804             0  \n",
      "20160             0  \n",
      "29239             1  \n",
      "23051             0  \n",
      "16411             0  \n"
     ]
    }
   ],
   "source": [
    "algorithms = [\"ADA\", \"ALS\", \"PPageRank\", \"Personalized\"]\n",
    "for algorithm in algorithms:\n",
    "    print(\"\\n\\nTop-5 recommendations from {} algoritm\".format(algorithm))\n",
    "    top = get_topk(test_df, algorithm)\n",
    "    top[\"u\"] = top[\"u\"].replace(user_names_mapping)\n",
    "    top[\"v\"] = top[\"v\"].replace(user_names_mapping)\n",
    "    print(top[[\"u\", \"v\", algorithm, \"ground_truth\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Scores comparison - nDCG and precision@k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**nDCG**\n",
    "\n",
    "\n",
    "nDCG is used to asses the performance of ranking algorithms for categorical scores. It assumes that the added value of an element decreases as it is placed in lower positions of the ranking. \n",
    "\n",
    "To compute nDCG, we used a scoring from 0 to 3, being 3 the best score. \n",
    "For the ground truth, all 1 (indicating a link) have been replaced with the top score 3, while 0s (indication no direct link) have been left as the worst score 0. \n",
    "\n",
    "For the output of the algorithms, they have been mapped into the scale from 0 to 3 taking into account their minimum and maximum values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>ADA</th>\n",
       "      <th>ALS</th>\n",
       "      <th>PPageRank</th>\n",
       "      <th>Personalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8267</th>\n",
       "      <td>1096</td>\n",
       "      <td>12512</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12044</th>\n",
       "      <td>346</td>\n",
       "      <td>3550</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19585</th>\n",
       "      <td>1178</td>\n",
       "      <td>14583</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6235</th>\n",
       "      <td>1547</td>\n",
       "      <td>3550</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21086</th>\n",
       "      <td>9378</td>\n",
       "      <td>9670</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          u      v  ground_truth  ADA  ALS  PPageRank  Personalized\n",
       "8267   1096  12512             3    0    3          1             0\n",
       "12044   346   3550             3    0    3          0             2\n",
       "19585  1178  14583             3    0    3          1             0\n",
       "6235   1547   3550             3    0    3          0             2\n",
       "21086  9378   9670             3    0    3          0             0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transform continuous scores to categorical ones (from 0 to 3) being 3 the best score. \n",
    "\n",
    "def compute_intervals(df, column, n):\n",
    "    intervals = []\n",
    "    minimum = df[column].min()\n",
    "    maximum = df[column].max()\n",
    "    interval_length = (maximum - minimum) / (n + 1)\n",
    "    \n",
    "    for i in range(n + 1):\n",
    "        intervals.append((minimum + interval_length * i, minimum + interval_length * (i+1)))\n",
    "    return intervals\n",
    "\n",
    "def substitution (x, intervals):\n",
    "    for i, pos in enumerate(intervals): \n",
    "        if x >= pos[0] and x <= pos[1]:\n",
    "            return i\n",
    "        \n",
    "ranked_scores = test_df.copy()\n",
    "\n",
    "ranked_scores[\"ground_truth\"] = ranked_scores[\"ground_truth\"].apply(lambda x: 3 if x == 1 else 0)\n",
    "ranked_scores[\"ADA\"] = ranked_scores[\"ADA\"].apply(lambda x: substitution(x, compute_intervals(ranked_scores,\"ADA\",3)))\n",
    "ranked_scores[\"ALS\"] = ranked_scores[\"ALS\"].apply(lambda x: substitution(x, compute_intervals(ranked_scores,\"ALS\",3)))\n",
    "ranked_scores[\"PPageRank\"] = ranked_scores[\"PPageRank\"].apply(lambda x: substitution(x, compute_intervals(ranked_scores,\"PPageRank\",3)))\n",
    "ranked_scores[\"Personalized\"] = ranked_scores[\"Personalized\"].apply(lambda x: substitution(x, compute_intervals(ranked_scores,\"Personalized\",3)))\n",
    "\n",
    "ranked_scores.sort_values(by=\"ground_truth\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nDCG scores computation for each algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_at_k(y_true, y_score,  k=10):\n",
    "    order = np.argsort(y_score)[::-1] # get the list of indexes of the predicted score sorted in descending order.\n",
    "    y_true = np.take(list(y_true), order[:k]) # sort the actual relevance label of the documents based on predicted score(hint: np.take) and take first k.\n",
    "    gain = 2**(y_true) - 1 # Compute gain (use formula 7 above)\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2) # Compute denominator\n",
    "    return np.sum(gain / discounts) #return dcg@k\n",
    "\n",
    "\n",
    "def ndcg_at_k(y_true, y_score, k=10):    \n",
    "    dcg_max = dcg_at_k(y_true, y_true, k) # Ideal dcg\n",
    "    if not dcg_max:\n",
    "        return 0\n",
    "    return np.round(dcg_at_k(y_true, y_score, k) / dcg_max,4)  # return ndcg@k\n",
    "\n",
    "def compute_ndcg(df, column, topk = 20): \n",
    "    sorted_ = df.sort_values(by = column, ascending = False)\n",
    "    return ndcg_at_k(sorted_[\"ground_truth\"], sorted_[column], topk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDCG score ranking with ADA algorithm: 0.2914\n",
      "nDCG score ranking with ALS algorithm: 0.1141\n",
      "nDCG score ranking with PPageRank algorithm: 0.2048\n",
      "nDCG score ranking with Personalized algorithm: 0.4043\n"
     ]
    }
   ],
   "source": [
    "for algorithm in algorithms:\n",
    "    print(\"nDCG score ranking with {} algorithm: {}\".format(algorithm, compute_ndcg(ranked_scores, algorithm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision@k**\n",
    "\n",
    "p@20 score has also been used to compare the performance of the algorithms, by checking whether the top-20 link connections recommended by each algorithm are in the actual ground truth. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k (scores, column, topk = 20):\n",
    "    scores = get_topk(scores, column, topk)\n",
    "    return (scores[\"ground_truth\"].sum())/(topk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@20 of ADA algorithm: 0.25\n",
      "Precision@20 of ALS algorithm: 0.3\n",
      "Precision@20 of PPageRank algorithm: 0.35\n",
      "Precision@20 of Personalized algorithm: 0.3\n"
     ]
    }
   ],
   "source": [
    "k = 20\n",
    "for algorithm in algorithms:\n",
    "    print(\"Precision@{} of {} algorithm: {}\".format(k, algorithm, precision_at_k(test_df, algorithm, k)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
